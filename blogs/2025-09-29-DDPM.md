---
title: Denoising Diffusion Probabilistic Models
date: 2025-10-26
category: Diffusion
image: static/img/DDPMtn.png
summary: "Recently, there are many generative models using diffusion model. We can study from the start of diffusion model, DDPM!"
---

# I. Introduction and Motivation

*Authors* : Jonathan Ho, Ajay Jain, Pieter Abbeel (NeurlPS 2020)

## Abstraction

A diffusion probabilistic model ("Diffusion Model") that learns a reverse Markov chain to invert a fixed forward Gaussian nosing process, trained with variational bound. Small Gaussian steps in the forward process let the reverse transition be conditional Gaussian - yielding a simple neural parameterization. 

## Introduction (Simple)

Main concept of generation is "un-noising". Start with real data $x_0$ (ex. Image data). 

The **FORWARD** diffusion process adds tiny Gaussian noise step-by-step until signal is nearly destroyed.

A neural network then learns the reverse chain that denoises step-by-step back to data.

Because the forward steps are small and Gaussian, the reverse steps can also be modeled as Gaussians. 

## Mathematical Background

### 1st order Markov chain 

### Probability Marginality and 