---
title: Denoising Diffusion Probabilistic Models
date: 2025-10-26
category: Paper/Diffusion
image: static/img/DDPMtn.png
summary: "Recently, there are many generative models using diffusion model. We can study from the start of diffusion model, DDPM!"
---

Before reading this post, You can **think** about this questions.

" If we intentionally destroy data by adding noise (diffusion), can we really train a model to *reverse* the process?"

"And in doing so, Is it possible to create *high-quality* new samples from pure noise? What does this process mean in terms of *information theory perspective*?"

ðŸ““ **Paper** : Jonathan Ho, Ajay Jain, Pieter Abbeel (2020). Denoising Diffusion Probabilistic Models

ðŸ“š **Additional Reading materials (ex. Blog)** : Lilian Weng, What are Diffusion Models? (For broader context, acceleration, and guidance methods)


# I. SHORT SUMMARY

**Denoising Diffusion Probabilistic Models (DDPMs)** are a generative modeling framework based on a parameterized Markov chain. The model learns to reverse a fixed forward (diffusion) process, which gradually adds Gaussian noise to data until it becomes pure noise. The reverse chain starts from a standard Gaussian prior and learns to progressively denoise it back into a sample. 

This model's core innovation is parameterizing the reverse process to predict the noise at each step and simplifying the complex training objective function into a simple objective function. 


# II. MATHEMATICAL BACKGROUND 

This concepts are general concepts to understand this paper.

## II-1) 1st-Order Markov Process

A first-order Markov process (or Markov chain) is a stochastic model describing a sequence of possible events. 

The key property of the "Markov property" is that the probability of the next state depends only on the current state, not on the sequence of events that preceded it. 

$$p(x_t | x_{t-1}, x_{t-2}, ..., x_0) = p(x_t | x_{t-1})$$

This "memoryless" property dramatically simplifies the joint probability of a long chain, allowing it to be factored into a product of transition probabilities.

By joint probability (Chain Rule), This property allows the joint probability of an entire sequence to be factored into a product of conditional probabilities. This is fundamental to defining both the forward and reverse processes in DDPM.

$$
p(x_{0:T}) = p(x_0)\prod_{t=1}^{T}p(x_t \mid x_{t-1})
$$


## II-2. ELBO (Evidence Lower Bound)

In variational inference (VI), the data log-likelihood $log p\_\\theta (x)$ is often intractable.

The ELBO (Evidence Lower Bound) provides a computable lower bound.

By introducing an approximate posterior and applying Jensen's inequality, We can get following bounds.

$$ \\logÂ p\_{\\theta}(x)  
\=Â \\logÂ \\intÂ p\_{\\theta}(x,Â z)\\Â dz  
\=Â \\logÂ \\intÂ q(zÂ \\midÂ x)Â \\frac{p\_{\\theta}(x,Â z)}{q(zÂ \\midÂ x)}\\Â dz  
\\ge \\int q(z \\mid x) \\log \\frac{p\_{\\theta}(x, z)}{q(z \\mid x)}\\ dz Â $$Â 

## II-3. KL Divergence of Gaussians

DDPMs assume **Gaussian distributions** for both the forward and reverse processes.

This means that the terms in the ELBO often reduce to computing the KL divergence between two Gaussians.

For two multivariate normal distributions $q \\sim \\mathcal{N}(\\mu\_q, \\sigma\_q^2)$ and $p \\sim \\mathcal{N}(\\mu\_p, \\sigma\_p^2)$, the KL divergence has a convenient closed-form solution.

$$D\_{KL}(q \\parallel p) = \\left( \\log \\frac{\\sigma\_p}{\\sigma\_q} + \\frac{\\sigma\_q^2 + (\\mu\_q - \\mu\_p)^2}{2\\sigma\_p^2} - \\frac{1}{2} \\right)$$


# III. Diffusion Model

A DDPM is a latent variable model by Forward Process and Reverse Process.


## III-1) Forward and Reverse Process


![Figure 1](static/img/DDPM/DDPM.png)


Forward and reverse process are both Markovian processes.

(1) **Forward Process** $q$ (Diffusion) : This is a **fixed** process with no learnable parameters that gradually adds Gaussian noise to an image $x\_0$ over $T$ steps according to a variance schedule $\\beta\_t$.  
  
$$q(x\_t|x\_{t-1})Â :=Â \\mathcal{N}(x\_t;Â \\sqrt{1-\\beta\_t}x\_{t-1},Â \\beta\_t\\mathbf{I})$$  
A key property is that we can sample $x\_t$ at any arbitrary timestep directly from $x\_0$.Â   
  
Defining $\\alpha\_t := 1 - \\beta\_t$ andÂ Â $\\bar{\\alpha}\_t := \\prod\_{s=1}^t \\alpha\_s$, we have the closed form of $q$.  
  
$$q(x\_t|x\_0)Â =Â \\mathcal{N}(x\_t;Â \\sqrt{\\bar{\\alpha}\_t}x\_0,Â (1-\\bar{\\alpha}\_t)\\mathbf{I})$$Â   
  
Â ThisÂ makesÂ trainingÂ highlyÂ efficient,Â asÂ weÂ canÂ sampleÂ aÂ randomÂ $t$Â forÂ eachÂ trainingÂ example.  
  
(2) **Reverse Process** $p\_\\theta$ (Denoising) : This is a **learned** Markov chain that aims to reverse the diffusion, starting from pure noise $x\_T \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ and progressively generating a data sample.  
Â $$p\_\\theta(x\_{t-1}|x\_t) := \\mathcal{N}(x\_{t-1}; \\mu\_\\theta(x\_t, t), \\mathbf{\\Sigma}\_\\theta(x\_t, t))$$

### III-2. Loss Function (Objective Function)

The model is trained by optimizing the variational bound (similar with ELBO) on the negative log-likelihood.Â 

![Figure 2](static/img/DDPM/Loss.png)

The paper shows this bound $L$ can be rewritten as a sum of KL divergences.

![Figure 3](static/img/DDPM/figure3.png)

If you want to understand mathematical derivation, you can drive a **Loss function** to follow this equations.

![Figure 4](static/img/DDPM/figure4.png)

Let's look at three terms in $L$ (Objective Function)!

(1) **First Term of Objective Function** : **$L\_T$** is constant because in this paper's implementation, $q$ has no learnable parameters and tractable distribution $q(x\_T | x\_0)$ and prior $p(x\_T)$ are very similar. So, The first term of $L$ ($L\_T$) can be ignored.

(2) **Second Term of Objective Function** : **$L\_{t-1}$**

Â **- What is the $q(x\_{t-1} | x\_t, x\_0)$?**

![Figure 5](static/img/DDPM/figure5.png)

(Why? )

![Figure 6](static/img/DDPM/figure6.png)

**\- What is the $p\_\\theta (x\_t-1 | x\_t)$?**

By Definition of this paper,Â 

![Figure 7](static/img/DDPM/figure7.png)

**\-** **What is the KL Divergence of two distribution?**

$p\_\\theta (x\_t-1 | x\_t)$ and $q(x\_{t-1} | x\_t, x\_0)$ are both Gaussian Distribution.

****From III-3, you can derive this equation.****

![Figure 8](static/img/DDPM/figure8.png)

![Figure 9](static/img/DDPM/figure9.png)

By this mathematics derivation, If we follow Algorithm 2, we can sample $x\_0$ from $x\_T$.Â 

![Figure 10](static/img/DDPM/figure10.png)

and we can finally get $L\_{t-1} - C$, but more simple version. ($C$ is a constant not depending on $\\theta$)Â 

![Figure 11](static/img/DDPM/figure11.png)

(3) **Third Term of Objective Function** : **$L\_0$**Â 

**$L\_0$ is the final reconstruction log-likelihood term. In this paper, image data should be integers scaled linearly in \[-1,1\].**Â 

![Figure 12](static/img/DDPM/figure12.png)

### III-3. Simple Verison of Loss Function and Training

Can't you make it simpler? Of course you can!

![Figure 13](static/img/DDPM/figure13.png)

It was a very difficult process to get here. But you will get $L\_{simple}$ Version to train by Algorithm 1.

![Figure 14](static/img/DDPM/figure14.png)

So, This simplification effectively **ignores the complex weighting coefficient** from the true variational bound.Â 

### IV. UNDERSTANDING DDPM THROUGH INFORMATION THEORY

DDPM's Information-theoretic story starts from Variation bound. (What is the DDPM's Variation bound? Equation 5 : a sum of Gaussian KL terms across timesteps plus a terminal reconstruction term.) and you can connect to autoregressive decoding.

![Figure 15](static/img/DDPM/figure15.png)

### IV-1. Rate-distortion curve

![Figure 16](static/img/DDPM/figure16.png)

On the rate-distortion curve (especially the third Curve), the curve is steep at the start.

**Large distortion reduction per bit!**

Then, Flattens as marginal bits are spent refining invisible texture rather than improving image quality.

For example,

![Figure 17](static/img/DDPM/figure17.png)

**ðŸ”¥** Why this matter?Â 

\- DDPMs can produce high-quality samples but still have non-competivity lossless codelengths versus other models. This is because most bits in the bound go to describing imperceptible details, revealing a lossy-compressor inductive bias.

### IV-2. Interpolation

![Figure 18](static/img/DDPM/figure18.png)

If you take a two image ($x\_t, x\_{t'} \\sim q(x\_t | x\_0)$), you can make noise images through the forward diffusion. You can linearly blend the resulting noises, and decode(reverse) with the learned reverse process. You can make high quality images by decoding a blended noise.

---

## V. MY THOUGHT

DDPM is amazing method to create high quality images from noisy images. What suprised me most is that the model doesn't predict the image directly. ðŸ˜² It predicts the noise at each step, which both simplifies the training objective and ties the sampler to a Langevin-like update.Â 

I also liked how the paper controls variance across timesteps. The forword diffusion is driven by a variance schedule (you choose this schedule), and in their implement, they fix $\\beta\_t$ as constants so the forward process has no leanable parameters. Correspondingly, The reverse variance is fixed for stability.




